## Архітектура для реальних завдань

Цей проект — не просто скрипт, а повноцінна платформа для вилучення даних, побудована на принципах розширюваності та відмовостійкості. Вона дозволяє швидко адаптуватися під будь-який цільовий сайт, мінімізуючи час на розробку нового парсера.

### Ключові можливості

*   **Робота з будь-якими сайтами:** Підтримка як статичних (через `requests`), так і складних динамічних сайтів, що активно використовують JavaScript (через `Playwright`).
*   **Обхід антибот-захисту:** Фреймворк готовий до ротації User-Agent, проксі-серверів та налаштування затримок для імітації поведінки людини.
*   **Авторизація та сесії:** Вбудована утиліта для збереження сесії після ручного логіну, що дозволяє парсити дані з особистих кабінетів та закритих розділів.
*   **Відмовостійкість:**
    *   **Інкрементальне збереження:** Дані негайно зберігаються в базу даних SQLite, що запобігає їх втраті при збоях.
    *   **Дедуплікація:** `UNIQUE` constraint у базі даних гарантує відсутність дублікатів.
    *   **Автоматичні ретраї:** Вбудовані повторні спроби для мережевих запитів у разі тимчасових збоїв.
*   **Гнучкість:** Нові парсери додаються створенням лише двох файлів (конфіг + клас парсера) без зміни ядра системи.
*   **Відтворюваність:** Повна контейнеризація з Docker. Скрапер запускається однією командою на будь-якій машині.```

### Дисклеймер
Весь веб-скрапінг та робота з даними ведуться виключно відповідно до чинного законодавства, умов використання (ToS) конкретного сайту та офіційних API-інтерфейсів.

- Соціальні мережі та сервіси збираються **тільки через офіційні API**, якщо вони надані.
- Конфіденційна інформація обробляється **тільки у рамках клієнтів замовника**.
- Збір персональних даних третіх осіб поза бізнесом замовника не здійснюється.
- Не порушуються авторські права, обмеження доступу та технічні заходи захисту.
- Методи, що використовуються, прозорі, безпечні і не завдають шкоди стороннім сервісам.