## Архитектура для реальных задач

Этот проект — не просто скрипт, а полноценная платформа для извлечения данных, построенная на принципах расширяемости и отказоустойчивости. Она позволяет быстро адаптироваться под любой целевой сайт, минимизируя время на разработку нового парсера.

### Ключевые возможности

*   **Работа с любыми сайтами:** Поддержка как статических (через `requests`), так и сложных динамических сайтов, активно использующих JavaScript (через `Playwright`).
*   **Обход антибот-защиты:** Фреймворк готов к ротации User-Agent, прокси-серверов и настройке задержек для имитации поведения человека.
*   **Авторизация и сессии:** Встроена утилита для сохранения сессии после ручного логина, что позволяет парсить данные из личных кабинетов и закрытых разделов.
*   **Отказоустойчивость:**
    *   **Инкрементальное сохранение:** Данные немедленно сохраняются в базу данных SQLite, что предотвращает их потерю при сбоях.
    *   **Дедупликация:** `UNIQUE` constraint в базе данных гарантирует отсутствие дубликатов.
    *   **Автоматические ретраи:** Встроены повторные попытки для сетевых запросов при временных сбоях.
*   **Гибкость:** Новые парсеры добавляются созданием всего двух файлов (конфиг + класс парсера) без изменения ядра системы.
*   **Воспроизводимость:** Полная контейнеризация с Docker. Скрапер запускается одной командой на любой машине.

### Дисклеймер
Весь веб-скрапинг и работа с данными ведутся исключительно в соответствии с действующим законодательством, условиями использования (ToS) конкретного сайта и официальными API-интерфейсами.

- Социальные сети и сервисы собираются **только через официальные API**, если они предоставлены.    
- Конфиденциальная информация обрабатывается **только в рамках клиентов заказчика**.    
- Сбор персональных данных **третьих лиц вне бизнеса заказчика** не осуществляется.    
- Не нарушаются авторские права, ограничения доступа и технические меры защиты.    
- Используемые методы прозрачны, безопасны и не наносят ущерба сторонним сервисам.